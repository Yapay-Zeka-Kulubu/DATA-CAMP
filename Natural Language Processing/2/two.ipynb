{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Duygu Analizi (Sentiment Analysis) - Makine Öğrenmesi\n",
                "\n",
                "Bu not defterinde, kendi oluşturduğumuz küçük bir veri seti üzerinde makine öğrenmesi yöntemleri kullanarak duygu analizi yapacağız."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "from sklearn.feature_extraction.text import CountVectorizer\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.naive_bayes import MultinomialNB\n",
                "from sklearn.metrics import accuracy_score"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Veri Seti Oluşturma\n",
                "Örnek olarak küçük bir Türkçe veri seti oluşturuyoruz."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "data = {\n",
                "    'text': [\n",
                "        'Bu film harika', 'Çok beğendim', 'Mükemmel bir ürün', 'Kesinlikle tavsiye ederim', 'Çok güzel',\n",
                "        'Hiç beğenmedim', 'Berbat bir deneyim', 'Zaman kaybı', 'Çok kötü', 'Tavsiye etmem',\n",
                "        'Oyunculuklar şahaneydi', 'Senaryo çok sürükleyici', 'Görüntü kalitesi muazzam',\n",
                "        'Sıkıcı bir filmdi', 'Param boşa gitti', 'Beklentimi karşılamadı'\n",
                "    ],\n",
                "    'label': [\n",
                "        'Pozitif', 'Pozitif', 'Pozitif', 'Pozitif', 'Pozitif',\n",
                "        'Negatif', 'Negatif', 'Negatif', 'Negatif', 'Negatif',\n",
                "        'Pozitif', 'Pozitif', 'Pozitif',\n",
                "        'Negatif', 'Negatif', 'Negatif'\n",
                "    ]\n",
                "}\n",
                "\n",
                "df = pd.DataFrame(data)\n",
                "print(\"Veri Seti:\")\n",
                "print(df)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Veri Ön İşleme ve Vektörleştirme\n",
                "Metin verilerini makine öğrenmesi modelinin anlayabileceği sayısal formata çeviriyoruz (Bag of Words modeli)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "vectorizer = CountVectorizer()\n",
                "X = vectorizer.fit_transform(df['text'])\n",
                "y = df['label']\n",
                "\n",
                "print(\"Öznitelik İsimleri (Kelime Hazinesi):\")\n",
                "print(vectorizer.get_feature_names_out())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Model Eğitimi\n",
                "Veriyi eğitim ve test olarak ayırıp Naive Bayes modeli ile eğitiyoruz."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Eğitim ve Test Setlerine Ayırma\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                "\n",
                "# Model Eğitimi (Multinomial Naive Bayes)\n",
                "model = MultinomialNB()\n",
                "model.fit(X_train, y_train)\n",
                "\n",
                "# Test Seti Üzerinde Değerlendirme\n",
                "y_pred = model.predict(X_test)\n",
                "print(f\"\\nModel Doğruluğu: {accuracy_score(y_test, y_pred)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Yeni Veri ile Tahmin\n",
                "Modeli daha önce görmediği cümlelerle test ediyoruz."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "yeni_yorumlar = [\"Bu ürünü çok sevdim\", \"Hiç güzel değil\", \"Fena değil ama daha iyi olabilirdi\", \"Tam bir hayal kırıklığı\"]\n",
                "yeni_vektor = vectorizer.transform(yeni_yorumlar)\n",
                "tahminler = model.predict(yeni_vektor)\n",
                "\n",
                "print(\"\\nYeni Yorumlar ve Tahminler:\")\n",
                "for yorum, tahmin in zip(yeni_yorumlar, tahminler):\n",
                "    print(f\"Yorum: '{yorum}' -> Tahmin: {tahmin}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. RNN (Recurrent Neural Network) ile Duygu Analizi\n",
                "Aynı veri seti üzerinde Derin Öğrenme yöntemi olan RNN kullanarak model eğiteceğiz."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from tensorflow.keras.preprocessing.text import Tokenizer\n",
                "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
                "from tensorflow.keras.models import Sequential\n",
                "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, LSTM\n",
                "\n",
                "# Parametreler\n",
                "vocab_size = 1000 # Kelime hazinesi büyüklüğü\n",
                "embedding_dim = 16\n",
                "max_length = 20 # Maksimum cümle uzunluğu\n",
                "trunc_type = 'post'\n",
                "padding_type = 'post'\n",
                "oov_tok = \"<OOV>\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Tokenization (Metni sayısal dizilere çevirme)\n",
                "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
                "tokenizer.fit_on_texts(df['text'])\n",
                "word_index = tokenizer.word_index\n",
                "\n",
                "sequences = tokenizer.texts_to_sequences(df['text'])\n",
                "padded = pad_sequences(sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
                "\n",
                "print(\"Padded Sequences:\")\n",
                "print(padded)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Etiketleri hazırlama (Pozitif=1, Negatif=0)\n",
                "labels = np.array([1 if label == 'Pozitif' else 0 for label in df['label']])\n",
                "\n",
                "# Eğitim ve Test ayırma\n",
                "X_train_rnn, X_test_rnn, y_train_rnn, y_test_rnn = train_test_split(padded, labels, test_size=0.2, random_state=42)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# RNN Modelini Oluşturma\n",
                "model_rnn = Sequential([\n",
                "    Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
                "    SimpleRNN(32),\n",
                "    Dense(1, activation='sigmoid')\n",
                "])\n",
                "\n",
                "model_rnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
                "model_rnn.summary()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Modeli Eğitme\n",
                "history = model_rnn.fit(X_train_rnn, y_train_rnn, epochs=50, validation_data=(X_test_rnn, y_test_rnn), verbose=1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test etme\n",
                "loss, accuracy = model_rnn.evaluate(X_test_rnn, y_test_rnn)\n",
                "print(f\"RNN Model Doğruluğu: {accuracy}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. LSTM (Long Short-Term Memory) ile Duygu Analizi\n",
                "RNN'in gelişmiş bir versiyonu olan LSTM kullanarak model eğiteceğiz. LSTM, uzun vadeli bağımlılıkları öğrenmede daha başarılıdır."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# LSTM Modelini Oluşturma\n",
                "model_lstm = Sequential([\n",
                "    Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
                "    LSTM(32),\n",
                "    Dense(1, activation='sigmoid')\n",
                "])\n",
                "\n",
                "model_lstm.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
                "model_lstm.summary()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Modeli Eğitme\n",
                "history_lstm = model_lstm.fit(X_train_rnn, y_train_rnn, epochs=50, validation_data=(X_test_rnn, y_test_rnn), verbose=1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test etme\n",
                "loss, accuracy = model_lstm.evaluate(X_test_rnn, y_test_rnn)\n",
                "print(f\"LSTM Model Doğruluğu: {accuracy}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}