<<<<<<< HEAD
# ðŸ¤– Yapay Zeka KulÃ¼bÃ¼ â€“ Streamlit RAG Chatbot

Bu proje, **Streamlit** tabanlÄ±, **Groq LLM API** kullanan ve **RAG (Retrieval-Augmented Generation)** mimarisiyle Ã§alÄ±ÅŸan bir sohbet uygulamasÄ±dÄ±r.

KullanÄ±cÄ±:

* Ã‡oklu sohbet (chat history)
* Dosya yÃ¼kleme (PDF / TXT / DOCX)
* Dosya iÃ§eriÄŸine dayalÄ± soru-cevap
  Ã¶zelliklerini kullanabilir.

---

## ðŸš€ Ã–zellikler

* ðŸ“‚ PDF / TXT / DOCX dosya yÃ¼kleme
* ðŸ’¬ Ã‡oklu sohbet yÃ¶netimi
* ðŸ§  Dosya iÃ§eriÄŸine dayalÄ± akÄ±llÄ± cevaplar (RAG)
* âš¡ Groq (LLaMA tabanlÄ±) hÄ±zlÄ± LLM entegrasyonu
* ðŸŽ¨ Ã–zelleÅŸtirilmiÅŸ Streamlit arayÃ¼zÃ¼

---

## ðŸ§  RAG (Retrieval-Augmented Generation) Mimarisi

Bu bÃ¶lÃ¼m iki parÃ§adan oluÅŸur:

1. **Bu projede kullanÄ±lan RAG yaklaÅŸÄ±mÄ±**
2. **Standart (klasik) RAG mimarisi** ve Ã¶ÄŸrenilmesi gereken kritik noktalar

---

## 1ï¸âƒ£ Bu Projedeki RAG Mimarisi (Lightweight / Heuristic RAG)

Bu projede **Vector Database kullanÄ±lmadan**, hafif ama etkili bir RAG yaklaÅŸÄ±mÄ± uygulanmÄ±ÅŸtÄ±r.
AmaÃ§: **LLMâ€™e tÃ¼m dosyayÄ± vermek yerine, soruyla en alakalÄ± bÃ¶lÃ¼mÃ¼ vermek**.

### ðŸ“‚ Dosya Ä°ÅŸleme

* YÃ¼klenen dosya (PDF / TXT / DOCX) **ham metne** Ã§evrilir
* Metin `\n\n` kullanÄ±larak **paragraflara bÃ¶lÃ¼nÃ¼r**
* Ã‡ok kÄ±sa ve anlamsÄ±z paragraflar elenir

### ðŸ” Retrieval (Bilgi Getirme MantÄ±ÄŸÄ±)

KullanÄ±cÄ± soru sorduÄŸunda:

1. Soru **kÃ¼Ã§Ã¼k harfe Ã§evrilir** ve kelimelere ayrÄ±lÄ±r
2. Her paragraf iÃ§in ÅŸu skor hesaplanÄ±r:

```python
score = sum(1 for keyword in keywords if keyword in para_lower)
```

Yani:

* Soru kelimeleri paragraf iÃ§inde geÃ§iyorsa skor artar
* Skoru 0 olan paragraflar elenir

### ðŸ§  En Ä°lgili BaÄŸlamÄ±n SeÃ§ilmesi

* Paragraflar **skora gÃ¶re sÄ±ralanÄ±r**
* En iyi **ilk 5 paragraf** alÄ±nÄ±r
* Toplam baÄŸlam **maksimum 2000 karakterle sÄ±nÄ±rlandÄ±rÄ±lÄ±r**

EÄŸer hiÃ§bir eÅŸleÅŸme yoksa:

* DosyanÄ±n **ilk kÄ±smÄ±** fallback olarak kullanÄ±lÄ±r

### ðŸ§© Augmentation (Prompt ZenginleÅŸtirme)

Bulunan baÄŸlam, **system prompt** iÃ§ine eklenir:

> "AÅŸaÄŸÄ±daki dosya iÃ§eriÄŸine dayanarak cevap ver"

Bu sayede LLM:

* Dosya dÄ±ÅŸÄ±na Ã§Ä±kmaz
* HalÃ¼sinasyon (uydurma bilgi) ihtimali azalÄ±r
* Daha kontrollÃ¼ ve tutarlÄ± cevap verir

### âœ¨ Generation (Cevap Ãœretimi)

* Groq LLM kullanÄ±lÄ±r
* Son **3 mesaj** baÄŸlama eklenir
* Her mesaj **400 karakterle sÄ±nÄ±rlandÄ±rÄ±lÄ±r**
* `max_tokens = 2048`

Bu yaklaÅŸÄ±m:

* Context taÅŸmasÄ±nÄ± Ã¶nler
* PerformansÄ± artÄ±rÄ±r

---

## 2ï¸âƒ£ Standart (Klasik) RAG Mimarisi

Klasik RAG mimarisi **3 ana adÄ±mdan** oluÅŸur:

```
User Query
   â†“
Embedding (Query)
   â†“
Vector DB (Similarity Search)
   â†“
Relevant Documents
   â†“
Prompt + Context
   â†“
LLM Response
```

### ðŸ§± 1. Document Indexing (Offline AÅŸama)

Bu aÅŸama **Ã¶nceden** yapÄ±lÄ±r:

* DokÃ¼manlar parÃ§alara bÃ¶lÃ¼nÃ¼r (chunking)
* Her parÃ§a embeddingâ€™e Ã§evrilir
* Vector Databaseâ€™e kaydedilir

Ã–nemli parametreler:

* `chunk_size`
* `chunk_overlap`
* embedding modeli

ðŸ“Œ YanlÄ±ÅŸ chunk ayarÄ± â†’ kÃ¶tÃ¼ retrieval

---

### ðŸ” 2. Retrieval (Online AÅŸama)

KullanÄ±cÄ± soru sorduÄŸunda:

* Soru embeddingâ€™e Ã§evrilir
* Vector DBâ€™de **semantic similarity search** yapÄ±lÄ±r
* En benzer `top-k` parÃ§a seÃ§ilir

Ã–nemli kavramlar:

* cosine similarity
* top-k
* metadata filtering

ðŸ“Œ Bu aÅŸama RAGâ€™in **en kritik kÄ±smÄ±dÄ±r**

---

### ðŸ§  3. Generation

* SeÃ§ilen dokÃ¼manlar promptâ€™a eklenir
* LLM sadece bu baÄŸlama dayanarak cevap verir

Ã–nemli noktalar:

* Context length limiti
* Prompt engineering
* Kaynak dÄ±ÅŸÄ±na Ã§Ä±kmama (grounding)

---

## ðŸŽ¯ RAG Ã–ÄŸrenirken Bilinmesi Gereken En Ã–nemli Konular

### âœ… Mutlaka Ã–ÄŸrenilmesi Gerekenler

* Chunking stratejileri
* Embedding nedir, nasÄ±l Ã§alÄ±ÅŸÄ±r
* Vector similarity (cosine, dot-product)
* Context window / token limiti
* Hallucination neden olur

### âš ï¸ En SÄ±k YapÄ±lan Hatalar

* TÃ¼m dokÃ¼manÄ± promptâ€™a koymak
* Ã‡ok bÃ¼yÃ¼k chunk kullanmak
* Retrieval kalitesini test etmemek
* Promptâ€™u kontrolsÃ¼z bÄ±rakmak

---

## ðŸ†š Bu Proje vs Klasik RAG

| Ã–zellik    | Bu Proje                    | Klasik RAG               |
| ---------- | --------------------------- | ------------------------ |
| Vector DB  | âŒ                           | âœ…                        |
| Embedding  | âŒ                           | âœ…                        |
| Kurulum    | Ã‡ok Kolay                   | Orta / Zor               |
| Performans | KÃ¼Ã§Ã¼k dosya iÃ§in iyi        | BÃ¼yÃ¼k veri iÃ§in mÃ¼kemmel |
| Ã–ÄŸrenme    | Yeni baÅŸlayanlar iÃ§in ideal | Production-ready         |

---

## ðŸ“Œ SonuÃ§

Bu proje:

* RAG mantÄ±ÄŸÄ±nÄ± **basit ve anlaÅŸÄ±lÄ±r** ÅŸekilde Ã¶ÄŸretir
* Streamlit + LLM entegrasyonunu gÃ¶sterir
* Klasik RAGâ€™e geÃ§iÅŸ iÃ§in saÄŸlam bir temel oluÅŸturur

ðŸš€
=======
# ðŸ¤– Yapay Zeka KulÃ¼bÃ¼ â€“ Streamlit RAG Chatbot

Bu proje, **Streamlit** tabanlÄ±, **Groq LLM API** kullanan ve **RAG (Retrieval-Augmented Generation)** mimarisiyle Ã§alÄ±ÅŸan bir sohbet uygulamasÄ±dÄ±r.

KullanÄ±cÄ±:

* Ã‡oklu sohbet (chat history)
* Dosya yÃ¼kleme (PDF / TXT / DOCX)
* Dosya iÃ§eriÄŸine dayalÄ± soru-cevap
  Ã¶zelliklerini kullanabilir.

---

## ðŸš€ Ã–zellikler

* ðŸ“‚ PDF / TXT / DOCX dosya yÃ¼kleme
* ðŸ’¬ Ã‡oklu sohbet yÃ¶netimi
* ðŸ§  Dosya iÃ§eriÄŸine dayalÄ± akÄ±llÄ± cevaplar (RAG)
* âš¡ Groq (LLaMA tabanlÄ±) hÄ±zlÄ± LLM entegrasyonu
* ðŸŽ¨ Ã–zelleÅŸtirilmiÅŸ Streamlit arayÃ¼zÃ¼

---

## ðŸ§  RAG (Retrieval-Augmented Generation) Mimarisi

Bu bÃ¶lÃ¼m iki parÃ§adan oluÅŸur:

1. **Bu projede kullanÄ±lan RAG yaklaÅŸÄ±mÄ±**
2. **Standart (klasik) RAG mimarisi** ve Ã¶ÄŸrenilmesi gereken kritik noktalar

---

## 1ï¸âƒ£ Bu Projedeki RAG Mimarisi (Lightweight / Heuristic RAG)

Bu projede **Vector Database kullanÄ±lmadan**, hafif ama etkili bir RAG yaklaÅŸÄ±mÄ± uygulanmÄ±ÅŸtÄ±r.
AmaÃ§: **LLMâ€™e tÃ¼m dosyayÄ± vermek yerine, soruyla en alakalÄ± bÃ¶lÃ¼mÃ¼ vermek**.

### ðŸ“‚ Dosya Ä°ÅŸleme

* YÃ¼klenen dosya (PDF / TXT / DOCX) **ham metne** Ã§evrilir
* Metin `\n\n` kullanÄ±larak **paragraflara bÃ¶lÃ¼nÃ¼r**
* Ã‡ok kÄ±sa ve anlamsÄ±z paragraflar elenir

### ðŸ” Retrieval (Bilgi Getirme MantÄ±ÄŸÄ±)

KullanÄ±cÄ± soru sorduÄŸunda:

1. Soru **kÃ¼Ã§Ã¼k harfe Ã§evrilir** ve kelimelere ayrÄ±lÄ±r
2. Her paragraf iÃ§in ÅŸu skor hesaplanÄ±r:

```python
score = sum(1 for keyword in keywords if keyword in para_lower)
```

Yani:

* Soru kelimeleri paragraf iÃ§inde geÃ§iyorsa skor artar
* Skoru 0 olan paragraflar elenir

### ðŸ§  En Ä°lgili BaÄŸlamÄ±n SeÃ§ilmesi

* Paragraflar **skora gÃ¶re sÄ±ralanÄ±r**
* En iyi **ilk 5 paragraf** alÄ±nÄ±r
* Toplam baÄŸlam **maksimum 2000 karakterle sÄ±nÄ±rlandÄ±rÄ±lÄ±r**

EÄŸer hiÃ§bir eÅŸleÅŸme yoksa:

* DosyanÄ±n **ilk kÄ±smÄ±** fallback olarak kullanÄ±lÄ±r

### ðŸ§© Augmentation (Prompt ZenginleÅŸtirme)

Bulunan baÄŸlam, **system prompt** iÃ§ine eklenir:

> "AÅŸaÄŸÄ±daki dosya iÃ§eriÄŸine dayanarak cevap ver"

Bu sayede LLM:

* Dosya dÄ±ÅŸÄ±na Ã§Ä±kmaz
* HalÃ¼sinasyon (uydurma bilgi) ihtimali azalÄ±r
* Daha kontrollÃ¼ ve tutarlÄ± cevap verir

### âœ¨ Generation (Cevap Ãœretimi)

* Groq LLM kullanÄ±lÄ±r
* Son **3 mesaj** baÄŸlama eklenir
* Her mesaj **400 karakterle sÄ±nÄ±rlandÄ±rÄ±lÄ±r**
* `max_tokens = 2048`

Bu yaklaÅŸÄ±m:

* Context taÅŸmasÄ±nÄ± Ã¶nler
* PerformansÄ± artÄ±rÄ±r

---

## 2ï¸âƒ£ Standart (Klasik) RAG Mimarisi

Klasik RAG mimarisi **3 ana adÄ±mdan** oluÅŸur:

```
User Query
   â†“
Embedding (Query)
   â†“
Vector DB (Similarity Search)
   â†“
Relevant Documents
   â†“
Prompt + Context
   â†“
LLM Response
```

### ðŸ§± 1. Document Indexing (Offline AÅŸama)

Bu aÅŸama **Ã¶nceden** yapÄ±lÄ±r:

* DokÃ¼manlar parÃ§alara bÃ¶lÃ¼nÃ¼r (chunking)
* Her parÃ§a embeddingâ€™e Ã§evrilir
* Vector Databaseâ€™e kaydedilir

Ã–nemli parametreler:

* `chunk_size`
* `chunk_overlap`
* embedding modeli

ðŸ“Œ YanlÄ±ÅŸ chunk ayarÄ± â†’ kÃ¶tÃ¼ retrieval

---

### ðŸ” 2. Retrieval (Online AÅŸama)

KullanÄ±cÄ± soru sorduÄŸunda:

* Soru embeddingâ€™e Ã§evrilir
* Vector DBâ€™de **semantic similarity search** yapÄ±lÄ±r
* En benzer `top-k` parÃ§a seÃ§ilir

Ã–nemli kavramlar:

* cosine similarity
* top-k
* metadata filtering

ðŸ“Œ Bu aÅŸama RAGâ€™in **en kritik kÄ±smÄ±dÄ±r**

---

### ðŸ§  3. Generation

* SeÃ§ilen dokÃ¼manlar promptâ€™a eklenir
* LLM sadece bu baÄŸlama dayanarak cevap verir

Ã–nemli noktalar:

* Context length limiti
* Prompt engineering
* Kaynak dÄ±ÅŸÄ±na Ã§Ä±kmama (grounding)

---

## ðŸŽ¯ RAG Ã–ÄŸrenirken Bilinmesi Gereken En Ã–nemli Konular

### âœ… Mutlaka Ã–ÄŸrenilmesi Gerekenler

* Chunking stratejileri
* Embedding nedir, nasÄ±l Ã§alÄ±ÅŸÄ±r
* Vector similarity (cosine, dot-product)
* Context window / token limiti
* Hallucination neden olur

### âš ï¸ En SÄ±k YapÄ±lan Hatalar

* TÃ¼m dokÃ¼manÄ± promptâ€™a koymak
* Ã‡ok bÃ¼yÃ¼k chunk kullanmak
* Retrieval kalitesini test etmemek
* Promptâ€™u kontrolsÃ¼z bÄ±rakmak

---

## ðŸ†š Bu Proje vs Klasik RAG

| Ã–zellik    | Bu Proje                    | Klasik RAG               |
| ---------- | --------------------------- | ------------------------ |
| Vector DB  | âŒ                           | âœ…                        |
| Embedding  | âŒ                           | âœ…                        |
| Kurulum    | Ã‡ok Kolay                   | Orta / Zor               |
| Performans | KÃ¼Ã§Ã¼k dosya iÃ§in iyi        | BÃ¼yÃ¼k veri iÃ§in mÃ¼kemmel |
| Ã–ÄŸrenme    | Yeni baÅŸlayanlar iÃ§in ideal | Production-ready         |

---

## ðŸ“Œ SonuÃ§

Bu proje:

* RAG mantÄ±ÄŸÄ±nÄ± **basit ve anlaÅŸÄ±lÄ±r** ÅŸekilde Ã¶ÄŸretir
* Streamlit + LLM entegrasyonunu gÃ¶sterir
* Klasik RAGâ€™e geÃ§iÅŸ iÃ§in saÄŸlam bir temel oluÅŸturur

ðŸš€
>>>>>>> a815bb6 (Hafta 4 - IMDb Sentiment Analysis Ã¶devi)
